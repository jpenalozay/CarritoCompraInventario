# ü§ñ Componente de Reinforcement Learning para E-commerce

Este componente implementa un sistema de recomendaci√≥n din√°mico usando **Reinforcement Learning** para optimizar las recomendaciones de productos en tiempo real, maximizando la conversi√≥n y el valor del carrito de compras.

## üéØ Problema Resuelto

**Optimizaci√≥n de Recomendaciones de Productos:**
- El agente RL aprende qu√© tipos de recomendaciones funcionan mejor para diferentes perfiles de clientes
- Se adapta din√°micamente al comportamiento del usuario
- Maximiza m√©tricas como conversi√≥n, revenue y engagement

## üèóÔ∏è Arquitectura del Componente

```mermaid
graph TD
    A[Flink] --> B[Cassandra]
    A --> C[Redis]
    B --> D[RL Feature Extractor]
    C --> D
    D --> E[RL Agent]
    E --> F[Recommendation Engine]
    F --> G[RL API]
    G --> H[Dashboard RL]
    G --> I[Frontend Principal]
    
    subgraph "RL Component"
        D
        E
        F
        G
        H
    end
```

## üìä Tablas de Cassandra para RL

### **rl_agent_state**
Almacena el estado del agente RL en cada paso de decisi√≥n.

### **rl_recommendations**
Historial de recomendaciones generadas con m√©tricas de rendimiento.

### **rl_rewards_history**
Registro de recompensas recibidas para entrenamiento del modelo.

### **rl_model_metrics**
M√©tricas de rendimiento del modelo (conversi√≥n, revenue, etc.).

### **shopping_cart_state**
Estado del carrito de compras para an√°lisis contextual.

### **user_interaction_events**
Eventos de interacci√≥n del usuario para features.

### **rl_policy_store**
Pol√≠ticas del agente (epsilon-greedy, softmax, UCB).

## üß† Algoritmo de Reinforcement Learning

### **Estado (State)**
- Cart total y n√∫mero de items
- Tiempo en sesi√≥n
- Preferencias de categor√≠as
- Sensibilidad al precio
- Nivel de engagement
- Contexto temporal (hora, d√≠a)

### **Acciones (Actions)**
- `low_price`: Recomendar productos de bajo precio
- `medium_price`: Recomendar productos de precio medio
- `high_price`: Recomendar productos de alto precio
- `popular`: Recomendar productos populares
- `personalized`: Recomendaci√≥n personalizada

### **Recompensas (Rewards)**
- **Conversi√≥n**: +1.0 si el usuario compra
- **Revenue**: Proporcional al valor de la compra
- **Engagement**: +0.5 por interacci√≥n positiva
- **Retenci√≥n**: +0.3 si el usuario regresa

### **Pol√≠tica de Exploraci√≥n**
- **Epsilon-Greedy**: 10% exploraci√≥n, 90% explotaci√≥n
- **Learning Rate**: 0.01
- **Discount Factor**: 0.95

## üöÄ Instalaci√≥n y Configuraci√≥n

### **1. Dependencias**
```bash
cd 7.0_rl
pip install -r requirements.txt
```

### **2. Variables de Entorno**
```bash
# Cassandra
CASSANDRA_HOST=cassandra
CASSANDRA_PORT=9042

# Redis
REDIS_HOST=redis
REDIS_PORT=6379

# RL API
RL_API_PORT=5000
DASH_PORT=8050
```

### **3. Inicializaci√≥n de Tablas**
```bash
# Ejecutar script de inicializaci√≥n
cqlsh -f src/init_rl_tables.cql cassandra 9042
```

## üåê API REST

### **Endpoints Principales**

#### **GET /health**
Health check del servicio RL.

#### **POST /api/v1/rl/recommendations**
Generar recomendaciones para un cliente.
```json
{
  "customer_id": "CUST001",
  "session_id": "session_123"
}
```

#### **POST /api/v1/rl/reward**
Enviar recompensa para entrenar el agente.
```json
{
  "customer_id": "CUST001",
  "session_id": "session_123",
  "reward_value": 1.0,
  "action_type": "low_price",
  "recommended_products": ["PROD1", "PROD2"],
  "confidence_score": 0.85
}
```

#### **GET /api/v1/rl/metrics**
Obtener m√©tricas del modelo RL.
```
/api/v1/rl/metrics?model_version=v1.0&days=7
```

#### **GET /api/v1/rl/recommendations/history**
Historial de recomendaciones.
```
/api/v1/rl/recommendations/history?customer_id=CUST001&limit=10
```

#### **GET /api/v1/rl/agent/state**
Estado actual del agente RL.

## üìä Dashboard de RL

### **Caracter√≠sticas**
- **M√©tricas en Tiempo Real**: Q-table size, epsilon, learning rate
- **Gr√°ficos de Recompensas**: Evoluci√≥n por episodio
- **Distribuci√≥n de Acciones**: Frecuencia de cada tipo de acci√≥n
- **M√©tricas del Modelo**: Conversi√≥n, revenue, confidence
- **Generador de Recomendaciones**: Prueba interactiva
- **Historial de Rendimiento**: Tendencias temporales

### **Acceso**
- **URL**: http://localhost:8050
- **Actualizaci√≥n**: Cada 30 segundos
- **Interactividad**: Generaci√≥n de recomendaciones en tiempo real

## üîÑ Flujo de Datos

### **1. Ingesta de Datos**
```
Flink ‚Üí Cassandra (transacciones, m√©tricas)
Flink ‚Üí Redis (datos en tiempo real)
```

### **2. Extracci√≥n de Features**
```
Cassandra ‚Üí RL Feature Extractor
- Historial de compras
- Preferencias de categor√≠as
- M√©tricas de engagement
```

### **3. Generaci√≥n de Recomendaciones**
```
RL Agent ‚Üí Recommendation Engine
- An√°lisis del estado actual
- Selecci√≥n de acci√≥n √≥ptima
- Generaci√≥n de productos recomendados
```

### **4. Feedback y Aprendizaje**
```
User Interaction ‚Üí Reward Calculation
- Conversi√≥n ‚Üí +1.0
- Revenue ‚Üí Proporcional
- Engagement ‚Üí +0.5
```

## üéØ Casos de Uso

### **1. Recomendaci√≥n Personalizada**
- Cliente con alto engagement ‚Üí Acci√≥n `personalized`
- Cliente sensible al precio ‚Üí Acci√≥n `low_price`
- Cliente premium ‚Üí Acci√≥n `high_price`

### **2. Optimizaci√≥n de Conversi√≥n**
- A/B testing autom√°tico de estrategias
- Adaptaci√≥n a patrones temporales
- Optimizaci√≥n por segmento de cliente

### **3. Maximizaci√≥n de Revenue**
- Balance entre conversi√≥n y valor promedio
- Recomendaciones de productos complementarios
- Estrategias de up-selling inteligente

## üìà M√©tricas y KPIs

### **M√©tricas del Agente**
- **Q-Table Size**: N√∫mero de estados aprendidos
- **Epsilon**: Tasa de exploraci√≥n actual
- **Average Reward**: Recompensa promedio por episodio
- **Learning Rate**: Velocidad de aprendizaje

### **M√©tricas de Negocio**
- **Conversion Rate**: Tasa de conversi√≥n de recomendaciones
- **Revenue per Recommendation**: Revenue generado por recomendaci√≥n
- **Confidence Score**: Confianza del modelo en sus predicciones
- **Engagement Rate**: Tasa de engagement con recomendaciones

## üîß Configuraci√≥n Avanzada

### **Ajuste de Hiperpar√°metros**
```python
# En rl_agent.py
self.epsilon = 0.1          # Tasa de exploraci√≥n
self.learning_rate = 0.01   # Velocidad de aprendizaje
self.discount_factor = 0.95 # Factor de descuento
```

### **Personalizaci√≥n de Recompensas**
```python
# Definir funci√≥n de recompensa personalizada
def calculate_reward(self, action, result):
    base_reward = 0.0
    
    if result['conversion']:
        base_reward += 1.0
        base_reward += result['revenue'] * 0.01
    
    if result['engagement']:
        base_reward += 0.5
    
    return base_reward
```

### **Nuevas Acciones**
```python
# Agregar nuevas acciones al enum
class ActionType(Enum):
    RECOMMEND_LOW_PRICE = "low_price"
    RECOMMEND_MEDIUM_PRICE = "medium_price"
    RECOMMEND_HIGH_PRICE = "high_price"
    RECOMMEND_CATEGORY_MATCH = "category_match"
    RECOMMEND_POPULAR = "popular"
    RECOMMEND_PERSONALIZED = "personalized"
    RECOMMEND_SEASONAL = "seasonal"  # Nueva acci√≥n
    RECOMMEND_TRENDING = "trending"  # Nueva acci√≥n
```

## üöÄ Despliegue con Docker

### **1. Construir Imagen**
```bash
cd 7.0_rl
docker build -t ecommerce-rl .
```

### **2. Ejecutar Contenedor**
```bash
docker run -d \
  --name ecommerce-rl \
  --network ecommerce-network \
  -p 5000:5000 \
  -p 8050:8050 \
  -e CASSANDRA_HOST=cassandra \
  -e REDIS_HOST=redis \
  ecommerce-rl
```

### **3. Integraci√≥n con Docker Compose**
```yaml
rl-component:
  build:
    context: ./7.0_rl
    dockerfile: Dockerfile
  ports:
    - "5000:5000"
    - "8050:8050"
  environment:
    - CASSANDRA_HOST=cassandra
    - REDIS_HOST=redis
  depends_on:
    - cassandra
    - redis
```

## üîç Monitoreo y Debugging

### **Logs del Agente**
```bash
# Ver logs del contenedor RL
docker logs ecommerce-rl

# Ver logs espec√≠ficos de la API
docker exec ecommerce-rl tail -f /app/logs/rl_api.log
```

### **M√©tricas de Cassandra**
```sql
-- Ver estado del agente
SELECT * FROM rl_agent_state 
WHERE agent_id = 'recommendation_agent' 
ORDER BY state_timestamp DESC LIMIT 10;

-- Ver recomendaciones recientes
SELECT * FROM rl_recommendations 
ORDER BY recommendation_timestamp DESC LIMIT 10;

-- Ver m√©tricas del modelo
SELECT * FROM rl_model_metrics 
WHERE model_version = 'v1.0' 
ORDER BY metric_timestamp DESC LIMIT 10;
```

### **M√©tricas de Redis**
```bash
# Conectar a Redis
docker exec -it ecommerce-redis redis-cli

# Ver keys relacionadas con RL
KEYS *rl*
```

## üéì Aplicaciones en E-commerce

### **1. Recomendaci√≥n de Productos**
- **Contextual**: Basada en carrito actual
- **Personalizada**: Basada en historial del cliente
- **Temporal**: Adaptada a patrones de tiempo

### **2. Optimizaci√≥n de Precios**
- **Dynamic Pricing**: Ajuste de precios en tiempo real
- **Bundle Optimization**: Paquetes de productos optimizados
- **Discount Strategies**: Estrategias de descuento inteligentes

### **3. Gesti√≥n de Inventario**
- **Demand Prediction**: Predicci√≥n de demanda
- **Stock Optimization**: Optimizaci√≥n de niveles de stock
- **Supply Chain**: Optimizaci√≥n de cadena de suministro

### **4. Marketing Personalizado**
- **Campaign Optimization**: Optimizaci√≥n de campa√±as
- **Content Recommendation**: Recomendaci√≥n de contenido
- **Email Marketing**: Marketing por email personalizado

## üîÆ Futuras Mejoras

### **1. Algoritmos Avanzados**
- **Deep Q-Network (DQN)**: Para estados complejos
- **Actor-Critic**: Para pol√≠ticas continuas
- **Multi-Agent RL**: M√∫ltiples agentes cooperativos

### **2. Features Avanzadas**
- **Sentiment Analysis**: An√°lisis de sentimientos
- **Image Recognition**: Reconocimiento de im√°genes de productos
- **Natural Language Processing**: Procesamiento de descripciones

### **3. Escalabilidad**
- **Distributed Training**: Entrenamiento distribuido
- **Model Serving**: Servicio de modelos optimizado
- **A/B Testing**: Testing autom√°tico de modelos

## üìö Referencias

- [Reinforcement Learning in E-commerce](https://arxiv.org/abs/2003.00123)
- [Multi-Armed Bandits for Recommendations](https://ieeexplore.ieee.org/document/7344818)
- [Deep Reinforcement Learning for E-commerce](https://dl.acm.org/doi/10.1145/3219819.3219820)

---

**Desarrollado para el Trabajo Final de Maestr√≠a en Inteligencia Artificial - UNI - Grupo 5** 